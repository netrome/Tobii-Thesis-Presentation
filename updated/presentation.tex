\documentclass{beamer}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[acronym]{glossaries}
\makeglossaries
\newacronym{gan}{GAN}{Generative Adversarial Network}
\newacronym{gans}{GANs}{Generative Adversarial Networks}
\newacronym{vae}{VAE}{Variational Autoencoder}
\newacronym{vaes}{VAEs}{Variational Autoencoders}
\newacronym{mse}{MSE}{Mean Squared Error}
\newacronym{aevb}{AEVB}{Auto Encoding Variational Bayes}
\newacronym{cnn}{CNN}{Convolutional Neural Network}
\newacronym{cnns}{CNNs}{Convolutional Neural Networks}
\newacronym{is}{IS}{Inception Score}
\newacronym{fid}{FID}{Fréchet Inception Distance}
\newacronym{wgan}{WGAN}{Wasserstein GAN}
\newacronym{aegan}{AEGAN}{Autoencoding GAN}
\newacronym{roi}{ROI}{Region Of Interest}
\newacronym{vaegan}{VAEGAN}{Variational Autoencoder + Generative Adversarial Network}
  
\usepackage{../TobiiTemplate/beamerthemeTobii}

\title{Data Augmentation with Deep Generative Models}
\author{Mårten Nilsson}
\institute{Tobii}
\date{2018}

\begin{document}

% Tobii presentation of Mårtens GAN thesis project

% Sample frames --------------------------------------------------
\frame{\titlepage}

%\begin{sectionframe}
%    \frametitle{Frame title}
%    Section frame
%\end{sectionframe}
%
%\begin{messageframe}
%    \frametitle{Frame title}
%    message frame
%\end{messageframe}
%
%\messageslide{Message slide}
%
%\statementslide{Statement slide}{images/banana.png}
%\statementslideB{Statement slide B}{images/banana.png}
%
%\plainslide{Slide title}{Plain slide}
%
%\textandpicslideA{Title}{Text and pic slide A}{images/banana.png}
%\textandpicslideB{Title}{Text and pic slide B}{images/banana.png}
%
% Structure of presentation ------
% Agenda and subject presentation
% Establish importance of topic (why generative models?, what are they useful for?, why are we interested in them?)
% Establish problem formulation for generative models, includning some pitfalls (ill posed questions etc).
% Provide some backround knowledge
% Present the tested methods and results
% Interpret results
% Final remarks and conclusions

\plainslide{Outline}{
    \begin{itemize}
        \item Generative Modelling
        \item Deep Generative Models: GANs and VAEs
        \item Data augmentation with Deep Generative Models  % Talk about the current research
        \item Experiments and results
    \end{itemize}
}

\sectionslide{Generative Modelling}

\plainslide{What is a generative model?}{

    \begin{itemize}
        \item A model capable of producing data similar to what the model have been trained on
        \item Learns the distribution of the data 

            (in contrast to discriminative models)
        \item Example: Naive Bayes, Gaussian Mixtures, Hidden Markov Models etc. 
    \end{itemize}
}

\plainslide{Why do we care about generative modelling?}{
    \textit{"What I cannot create I do not understand"} 

    - Richard Feynman
    \begin{itemize}
        \item Compression
        \item Augmentation
        \item Anonymization (GDPR)
        \item Domain adaptation \pause

            - Both Apple and Google utilize it for gaze estimation
    \end{itemize}
}

\sectionslide{Deep Generative Models}

\plainslide{\acrfull{vaes}}{
    \begin{itemize}
        \item Consists of an encoder and a decoder
        \item These can be convolutional neural networks
        \item The encoder models $P(latent | data)$
        \item The decoder models $P(data | latent)$
        \item Model parameters learned through variational inference
        \item Trained with two objectives
            \begin{itemize}
                \item $P(latent | data)$ should be similar to a specific prior distribution $P(latent)$
                \item $P(data | latent)$ where $latent$ is sampled from $P(latent | data)$ should give a high likelihood to the conditioned data point
            \end{itemize}
    \end{itemize}
}

\plainslide{\acrfull{gans}}{

    \begin{itemize}
        \item Consists of a generator and a discriminator
        \item These can be convolutional neural networks
        \item The discriminator is trained to distinguish fake images from real images
        \item The generator is trained to fool the discriminator
    \end{itemize}
}

\plainslide{\acrshort{gans} in practice}{
    \begin{itemize}
        \item Notoriously unstable
        \item Non-convergence
        \item Mode-collapse
        \item Lots of variants proposed (\acrshort{wgan}, Progressive \acrshort{gan}, ACGAN, LSGAN, BEGAN, DRAGAN, DCGAN etc...)
        \item Difficult to compare different models due to a lack of good quantitative evaluation measures
    \end{itemize}
}

\sectionslide{Data Augmentation}

\plainslide{The question}{
    \textit{"Can deep generative models be applied to generate synthetic data sets that can be used to boost the performance of existing discriminative models?"}

    \vspace{1.5cm}

    In other words:

    "Can we generate \textbf{useful} data?"
}

\plainslide{Measuring the usability of the data}{
    \begin{itemize}
        \item Historically difficult to evaluate \acrshort{gans}
        \item Common measures are \acrlong{is} and \acrlong{fid}
        \item Both of these are only valid for ImageNet
        \item There is a need for a custom evaluation measure
    \end{itemize}
}

\plainslide{Evaluation by classification}{
    \begin{itemize}
        \item Introduce a discriminative network (pupil localization)
        \item Train this network on generated data and test on real data
            \begin{itemize}
                \item Usable and interpretable measure of data quality
                \item Extend this by changing the training and test data sets
            \end{itemize}
    \end{itemize}
}


\textandpicslideA{Generating annotated data}{
    \begin{itemize}
        \item Deep generative models are unsupervised
        \item The classifier needs annotated data
        \item But...
    \end{itemize}
}{images/misc/example_image.png}

\textandpicslideA{Generating annotated data}{
    The annotations can also be represented as images
}{images/misc/example_heatmap.png}

\textandpicslideA{Generating annotated data}{
    \begin{itemize}
        \item The data can be represented as 2-channel images
        \item This results in an unsupervised problem
        \item Generating annotations means increased complexity
    \end{itemize}
}{images/misc/example_cat.png}

\sectionslide{Experiments and Results}

\plainslide{Experiments}{
    The tested models:
    \begin{itemize}
        \item \acrshort{wgan}
        \item \acrshort{vae}
        \item \acrshort{aegan}
        \item (Progressive \acrshort{gan})
    \end{itemize}

    Main experiments perfromed on:
    \begin{itemize}
        \item Syntheteic data (blender)
        \item DeepGaze data 
    \end{itemize}

    Additional toy experiments: 
    \begin{itemize}
        \item MNIST
        \item Iris
    \end{itemize}
}

\plainslide{Network architectures (generator)}{
    \begin{table}[t]
        \centering
        \scalebox{0.8}{
            \begin{tabular}{|lll|}
                \hline
                %\multicolumn{3}{c}{Generator}           \\ 
                Operation          & Output shape     & Stride \\ \hline
                Input              & 128x1x1   & 1      \\
                Conv 4x4           & 128x4x4   & 1      \\
                Conv 3x3           & 128x4x4   & 1      \\ \hline
                Transpose Conv 2x2 & 128x8x8   & 2      \\
                Conv 3x3           & 112x8x8   & 1      \\ \hline
                Transpose Conv 2x2 & 11216x16   & 2      \\
                Conv 3x3           & 96x16x16   & 1      \\ \hline
                Transpose Conv 2x2 & 96x32x32   & 2      \\
                Conv 3x3           & 80x32x32   & 1      \\ \hline
                Transpose Conv 2x2 & 80x64x64   & 2      \\
                Conv 3x3           & 64x64x64   & 1      \\ \hline
                Transpose Conv 2x2 & 64x128x128   & 2      \\
                Conv 3x3           & 32x128x128   & 1      \\ \hline
                Transpose Conv 2x2 & 32x256x256   & 2      \\
                Conv 3x3           & 16x256x256   & 1      \\ \hline
                Conv 1x1           & 2x256x256 & 1        \\ \hline
            \end{tabular}
        }
    \end{table}
}

\plainslide{Network architectures (discriminator)}{
    \begin{table}[t]
        \centering
        \scalebox{0.8}{
            \begin{tabular}{|lll|}
                \hline
                %\multicolumn{3}{c}{Discriminator}           \\ 
                Operation          & Output shape     & Stride \\ \hline
                Input              & 2x256x256   & 1   \\
                Conv 1x1           & 16x256x256 & 1    \\ 
                Conv 3x3           & 32x256x256 & 1    \\ 
                Conv 2x2           & 32x128x128 & 2    \\ \hline
                Conv 3x3           & 64x128x128 & 1    \\ 
                Conv 2x2           & 64x64x64 & 2      \\ \hline
                Conv 3x3           & 80x64x64 & 1      \\ 
                Conv 2x2           & 80x32x32 & 2      \\ \hline
                Conv 3x3           & 96x32x32 & 1      \\ 
                Conv 2x2           & 96x16x16 & 2      \\ \hline
                Conv 3x3           & 112x16x16 & 1     \\ 
                Conv 2x2           & 112x8x8 & 2       \\ \hline
                Conv 3x3           & 128x8x8 & 1       \\ 
                Conv 2x2           & 128x4x4 & 2       \\ \hline
                Minibatch stddev
                Conv 3x3           & 128x4x4   & 1     \\
                Conv 4x4           & 128x1x1   & 1     \\ 
                Fully connected    & 1x1 & 1         \\ \hline
            \end{tabular}
        }
    \end{table}
}

\plainslide{Network architectures (transformer)}{
    \begin{table}[t]
        \centering
        \scalebox{0.8}{
            \begin{tabular}{|lll|}
                \hline
                %\multicolumn{3}{c}{Generator}           \\ 
                Operation           & Output shape  & Stride \\ \hline
                Input               & 1x256x256     & 1     \\
                Conv 1x1 (1)           & 16x256x256    & 1     \\
                Conv 3x3 (2)            & 32x128x128    & 2     \\    
                Conv 3x3 (3)           & 64x64x64    & 2     \\ 
                Conv 3x3 (4)           & 128x32x32    & 2    \\ 
                Conv 3x3 (5)           & 256x16x16    & 2    \\ 
                Conv 3x3 (6)           & 256x8x8     & 2    \\ 
                Conv 3x3            & 256x4x4    & 2    \\ \hline
                Transpose Conv 4x4 + (6)  & 256x8x8    & 2    \\
                Transpose Conv 4x4 + (5) & 256x16x16    & 2    \\
                Transpose Conv 4x4 + (4) & 128x32x32    & 2    \\
                Transpose Conv 4x4 + (3) & 64x64x64    & 2    \\
                Transpose Conv 4x4 + (2) & 32x128x128    & 2    \\
                Transpose Conv 4x4 + (1)  & 16x256x256    & 2    \\
                Conv 1x1            & 1x256x256    & 1     \\ \hline
            \end{tabular}
        }
    \end{table}
}

\messageslide{Progressive \acrshort{gan} failed on our data}

\statementslideB{Reference batch}{images/reference_6x4.png}

\statementslideB{WGAN}{images/generated/wasserstein_fake_6x4.png}

\statementslideB{VAE}{images/generated/vae_fake_6x4.png}

\statementslideB{AEGAN}{images/generated/aegan_fake_6x4.png}

\statementslideB{Reference batch}{images/ref_g6_6x4.png}

\statementslideB{WGAN}{images/generated/wgan_g6_6x4.png}

\statementslideB{VAE}{images/generated/vae_g6_6x4.png}

\statementslideB{AEGAN}{images/generated/aegan_g6_6x4.png}

\plainslide{Results: synthetic data}{

    \begin{table}[t]
        \centering
        \begin{subtable}{0.9\textwidth}
            \begin{tabular}{|l|lll|}
                \cline{2-4}
                \multicolumn{1}{c|}{} & \multicolumn{3}{c|}{\textbf{Jaccard distance}} \\ \hline
                \textbf{Training data} & \acrshort{wgan} & VAE & \acrshort{aegan} \\ \hline
                Fake & \num{0.8132} & \num{0.159} & \textbf{\num{0.148}} \\
                Fake + real & \num{0.1219} & \textbf{\num{0.0944}} & \num{0.1032} \\
                \hline
                Real & \multicolumn{3}{c|}{\num{0.09607}} \\
                \hline
            \end{tabular}
            \caption{Tested on the real test data.}
            \label{subtab:on_real}
        \end{subtable}
        \begin{subtable}{0.9\textwidth}
            \begin{tabular}{|l|lll|}
                \cline{2-4}
                \multicolumn{1}{c|}{} & \multicolumn{3}{c|}{\textbf{Jaccard distance}} \\ \hline
                \textbf{Training data} & \acrshort{wgan} & VAE & \acrshort{aegan} \\ \hline
                Fake & \textbf{\num{4.82e-5}} & \num{0.0133} & \num{0.0491} \\ 
                Real & \num{0.1855} & \textbf{\num{0.0264}} & \num{0.1225} \\ 
                \hline
            \end{tabular}
            \caption{Test data generated by the generative models.}
            \label{subtab:on_fake}
        \end{subtable}
    \end{table}
}

\plainslide{Results: DeepGaze data}{
    \begin{table}[t]
        \centering
        \begin{subtable}{0.9\textwidth}
            \begin{tabular}{|l|lll|}
                \cline{2-4}
                \multicolumn{1}{c|}{} & \multicolumn{3}{c|}{\textbf{Jaccard distance}} \\ \hline
                \textbf{Training data} & \acrshort{wgan} & VAE & \acrshort{aegan} \\ \hline
                Fake & \num{0.9966} & \num{0.3445} & \textbf{\num{0.2084}} \\
                Fake + real & \num{0.1215} & \textbf{\num{0.1151}} & \num{0.1221} \\
                \hline
                Real & \multicolumn{3}{c|}{\num{0.11456}} \\
                \hline
            \end{tabular}
            \caption{Tested on the real test data.}
        \end{subtable}
        \begin{subtable}{0.9\textwidth}
            \begin{tabular}{|l|lll|}
                \cline{2-4}
                \multicolumn{1}{c|}{} & \multicolumn{3}{c|}{\textbf{Jaccard distance}} \\ \hline
                \textbf{Training data} & \acrshort{wgan} & VAE & \acrshort{aegan} \\ \hline
                Fake & \textbf{\num{8.795e-6}} & \num{0.0284} & \num{0.0457} \\ 
                Real & \num{0.8798} & \num{0.1008} & \textbf{\num{0.0786}} \\ 
                \hline
            \end{tabular}
            \caption{Test data generated by the generative models.}
        \end{subtable}
    \end{table}
}

\plainslide{Results: toy experiments}{
    \begin{table}[t]
        \centering
        \label{tab:toy_experiments}
        \begin{subtable}{0.9\textwidth}
            \scalebox{0.7}{
                \begin{tabular}{|l|ll|ll|ll|ll|}
                    \cline{2-9}
                    \multicolumn{1}{c|}{ } & \multicolumn{2}{c|}{Baseline} & \multicolumn{2}{c|}{WGAN} & \multicolumn{2}{c|}{VAE} & \multicolumn{2}{c|}{AEGAN} \\ \cline{2-9}
                    \multicolumn{1}{c|}{} & Mean & Std & Mean & Std & Mean & Std & Mean & Std \\ \hline
                    Error rate ($\%$) & \num{32.00} & \num{3.0792} & \num{33.33333} & \num{3.399} & \num{30.666} & \num{4.38178} & \textbf{\num{28.80}} & \num{2.0221} \\
                    \hline
                \end{tabular}
            }
            \caption{Iris}
        \end{subtable}
        \begin{subtable}{0.9\textwidth}
            \scalebox{0.7}{
                \begin{tabular}{|l|lll|l|l|}
                    \cline{2-6}
                    \multicolumn{1}{c|}{} & Baseline 100 & Baseline 200 & Baseline 400 & VAE & AEGAN \\ \hline
                    Error rate ($\%$) & \num{0.90} & \num{1.02} & \num{0.87} & \num{1.33} & \textbf{\num{0.86}} \\ \hline
                \end{tabular}
            }
            \caption{MNIST}
        \end{subtable}
    \end{table}
}


\begin{sectionframe}
    \frametitle{Concluding Remarks}
        \begin{itemize}
            \item {\color[rgb]{1, 1, 1} Data augmentation using deep generative models is not feasible} \pause
            \item {\color[rgb]{1, 1, 1} ...but it is possible} 
        \end{itemize}
\end{sectionframe}


\statementslide{Questions?}{images/misc/opened.png}

\statementslide{Questions?}{images/misc/closed.png}

\statementslide{Thank you}{images/misc/opened.png}

\end{document}
